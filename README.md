
---

## ğŸ› ï¸ How to Run, Use VidSense

1. **Clone this repository**  
2. **Install dependencies*** 
3. Follow notebooks sequentially (or start from your last checkpoint):  
   - Generate or add raw videos  
   - Extract frames â†’ features â†’ build dataset â†’ train model â†’ evaluate â†’ inference  
4. To test on new video: place video in `new_videos/`, then run `inference_Predict.ipynb â†’ predicted activity will be printed.

---

## ğŸ“Š Results & Performance

- Successfully recognizes activities: walking, running, sitting, falling.  
- Provides confusion matrix & classification report for model evaluation (see `evaluation and confusion matrix.ipynb`).  
- Pipeline is modular â€” you can retrain or extend with more data, new classes, or realâ€‘world videos.

---

## ğŸ“š Tech Stack

- Python  
- TensorFlow (CNN + LSTM)  
- OpenCV (video processing)  
- NumPy, scikitâ€‘learn (data handling, splitting, evaluation)  
- Jupyter Notebook (stepâ€‘byâ€‘step workflow)  

---

## ğŸŒ Why itâ€™s Relevant here for UAE Employers / Recruiters

- Works for **safety, surveillance, smart buildings, elder care** â€” all highly relevant in UAEâ€™s growing smartâ€‘city and healthcare/retail sectors.  
- Shows **fullâ€‘stack ML skills** â€” not just models, but end-to-end data processing, engineering discipline, reproducible code.  
- Clear project structure and documentation â€” easy for future collaborators or stakeholders to understand and build upon.  

---

## ğŸš€ Next Steps (Future Work)

- Add support for **realâ€‘time webcam / CCTV input** for live activity detection.  
- Extend to **multi-person tracking or more activity classes**.  
- Integrate **alert/notification systems** (e.g., for falls or hazardous activities).   
