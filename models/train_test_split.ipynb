{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e39da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Features folder: D:\\VidSense\\data\\features\n",
      "✔ Dataset folder: D:\\VidSense\\data\\dataset\n"
     ]
    }
   ],
   "source": [
    "# Set absolute paths\n",
    "# -----------------------------\n",
    "# Using absolute paths avoids FileNotFound errors\n",
    "features_dir = Path(\"D:/VidSense/data/features\")\n",
    "dataset_dir = Path(\"D:/VidSense/data/dataset\")\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)  # create folder if missing\n",
    "\n",
    "print(\"✔ Features folder:\", features_dir)\n",
    "print(\"✔ Dataset folder:\", dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1653a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected labels: ['falling', 'running', 'sitting', 'walking']\n",
      "✔ Total videos loaded: 12\n"
     ]
    }
   ],
   "source": [
    "# Load all .npy feature sequences\n",
    "# -----------------------------\n",
    "X = []  # List to store feature sequences\n",
    "y = []  # List to store numeric labels\n",
    "label_map = {}  # Map label name -> number\n",
    "reverse_map = {}  # Map number -> label name\n",
    "\n",
    "# Detect all label folders (walking, running, etc.)\n",
    "labels = sorted([d.name for d in features_dir.iterdir() if d.is_dir()])\n",
    "print(\"Detected labels:\", labels)\n",
    "\n",
    "# Assign numeric labels and load each video’s features\n",
    "for idx, label in enumerate(labels):\n",
    "    label_map[label] = idx\n",
    "    reverse_map[idx] = label\n",
    "\n",
    "    label_dir = features_dir / label\n",
    "    files = list(label_dir.glob(\"*.npy\"))\n",
    "\n",
    "    for f in files:\n",
    "        arr = np.load(f)  # shape: (num_frames, 512)\n",
    "        X.append(arr)\n",
    "        y.append(idx)\n",
    "\n",
    "print(f\"✔ Total videos loaded: {len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee99930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max frames in any video: 12\n",
      "Feature dimension: 512\n",
      "✔ Final dataset shapes:\n",
      "X: (12, 12, 512)\n",
      "y: (12,)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences to same length\n",
    "# -----------------------------\n",
    "# CNN-LSTM requires all sequences to have the same number of frames\n",
    "max_len = max(seq.shape[0] for seq in X)  # find max frames across all videos\n",
    "feature_dim = X[0].shape[1]  # feature dimension (512)\n",
    "\n",
    "print(\"Max frames in any video:\", max_len)\n",
    "print(\"Feature dimension:\", feature_dim)\n",
    "\n",
    "# Create a zero-padded array for all videos\n",
    "X_padded = np.zeros((len(X), max_len, feature_dim), dtype='float32')\n",
    "\n",
    "for i, seq in enumerate(X):\n",
    "    X_padded[i, :seq.shape[0], :] = seq  # copy original features\n",
    "\n",
    "X = X_padded\n",
    "y = np.array(y, dtype='int')\n",
    "\n",
    "print(\"✔ Final dataset shapes:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35cea133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (9, 12, 512) (9,)\n",
      "Test shapes : (3, 12, 512) (3,)\n"
     ]
    }
   ],
   "source": [
    "#rain/Test split\n",
    "# -----------------------------\n",
    "# Note: If you have very few videos per class, remove stratify=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shapes :\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e218e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Dataset saved successfully to: D:\\VidSense\\data\\dataset\n",
      "Contents now: [WindowsPath('D:/VidSense/data/dataset/X_test.npy'), WindowsPath('D:/VidSense/data/dataset/X_train.npy'), WindowsPath('D:/VidSense/data/dataset/y_test.npy'), WindowsPath('D:/VidSense/data/dataset/y_train.npy')]\n"
     ]
    }
   ],
   "source": [
    "#Save datasets safely\n",
    "# -----------------------------\n",
    "np.save(dataset_dir / \"X_train.npy\", X_train)\n",
    "np.save(dataset_dir / \"X_test.npy\", X_test)\n",
    "np.save(dataset_dir / \"y_train.npy\", y_train)\n",
    "np.save(dataset_dir / \"y_test.npy\", y_test)\n",
    "\n",
    "print(\"✔ Dataset saved successfully to:\", dataset_dir)\n",
    "print(\"Contents now:\", list(dataset_dir.glob(\"*.npy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd213b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (VidSense)",
   "language": "python",
   "name": "vidsense_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
